{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from geopy.distance import great_circle\n",
    "from shapely.geometry import MultiPoint\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "import folium\n",
    "from folium.plugins import FastMarkerCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dbscan_clustering_canada:\n",
    "    def __init__(self, epsilon, min_samples,study_area_provinces,cluster_area_provinces):\n",
    "        self.epsilon = epsilon\n",
    "        self.min_samples = min_samples\n",
    "        self.study_area_provinces = study_area_provinces \n",
    "        self.cluster_area_provinces = cluster_area_provinces\n",
    "\n",
    "    def import_data(self):\n",
    "        data_path = r\".\\canadacities.csv\"\n",
    "        #data_pathr\"C:\\Users\\jua12849\\Documents\\GitHub\\GeospatialDataAnalysis\\canadacities.csv\"\n",
    "        canadian_cities = pd.read_csv(data_path)\n",
    "        datum = \"EPSG:4326\"\n",
    "\n",
    "        #create geodataframe containing data with all canadian cities and a point geometry column\n",
    "        geometry = [Point(xy) for xy in zip(canadian_cities[\"lng\"],canadian_cities[\"lat\"])]\n",
    "        gdf = gpd.GeoDataFrame(canadian_cities,crs=datum,geometry=geometry)\n",
    "\n",
    "        return gdf\n",
    "\n",
    "\n",
    "    def create_gdf_dictionary(self,gdf):\n",
    "        #create dictionary with complete data for each province\n",
    "        d = {}\n",
    "        for province in gdf.province_id.unique():\n",
    "            d[\"province_{}\".format(province)] = gdf.loc[gdf[\"province_id\"]==province]\n",
    "\n",
    "        return d\n",
    "\n",
    "    def obtain_provinces(self,d):\n",
    "        provinces = list(d.keys())\n",
    "            \n",
    "        return provinces\n",
    "\n",
    "\n",
    "    def create_numpy_dictionary(self,d,gdf,provinces):\n",
    "        #obtain province names as well as list of dictionary keys.\n",
    "\n",
    "        #obtain lat/long data for each province and the entire country as a numpy array.\n",
    "        d_lat_lon_numpy = {}\n",
    "        for province in provinces:\n",
    "            d_lat_lon_numpy[\"{}\".format(province)] = [d.get(province)[[\"lat\",\"lng\"]].to_numpy()]\n",
    "\n",
    "        d_lat_lon_numpy[\"Canada\"] = [gdf[[\"lat\",\"lng\"]].to_numpy()]\n",
    "\n",
    "        return d_lat_lon_numpy\n",
    "\n",
    "    def replace_dictionary(self,d_lat_lon_numpy,province,d):\n",
    "\n",
    "        d_lat_lon_numpy[\"{}\".format(province)] = [d.get(province)[[\"lat\",\"lng\"]].to_numpy()]\n",
    "        \n",
    "        return d_lat_lon_numpy\n",
    "\n",
    "\n",
    "    def get_centermost_point(self,cluster):\n",
    "        centroid = (MultiPoint(cluster).centroid.x, MultiPoint(cluster).centroid.y)\n",
    "        centermost_point = min(cluster, key=lambda point: great_circle(point, centroid).m)\n",
    "        return tuple(centermost_point)\n",
    "\n",
    "    def apply_DBSCAN(self,d_lat_lon_numpy,province,epsilon,min_samples,algorithm = 'ball_tree',metric='haversine'):\n",
    "        return d_lat_lon_numpy[\"{}\".format(province)].append(\n",
    "                {\"dbs_{}\".format(province):DBSCAN(eps=epsilon, min_samples=min_samples,algorithm = algorithm,metric=metric).fit(np.radians(d_lat_lon_numpy.get(province)[0]))})\n",
    "\n",
    "    def retrieve_labels(self,d_lat_lon_numpy,province):\n",
    "        return d_lat_lon_numpy[\"{}\".format(province)].append(\n",
    "                {\"{}_cluster_label\".format(province):d_lat_lon_numpy.get(province)[1][\"dbs_{}\".format(province)].labels_})\n",
    "\n",
    "    def obtain_cluster_labels(self,d_lat_lon_numpy,province):\n",
    "        return d_lat_lon_numpy[\"{}\".format(province)].append(\n",
    "                {\"{}_num_clusters\".format(province):len(set(d_lat_lon_numpy.get(province)[2][\"{}_cluster_label\".format(province)]))})\n",
    "\n",
    "    def obtain_clusters_numpy(self,d_lat_lon_numpy,province):\n",
    "        return d_lat_lon_numpy[\"{}\".format(province)].append(\n",
    "                {\"{}_clusters\".format(province):\n",
    "                pd.Series(d_lat_lon_numpy.get(province)[0][d_lat_lon_numpy.get(province)[2][\"{}_cluster_label\".format(province)] == n] for n in range(d_lat_lon_numpy[\"{}\".format(province)][3][\"{}_num_clusters\".format(province)]))})\n",
    "\n",
    "\n",
    "    def perform_dbscan(self,d_lat_lon_numpy,epsilon,min_samples,d):\n",
    "\n",
    "        #perform DBSCAN algorithm to each province separately as well as the entire country\n",
    "        for province in list(d_lat_lon_numpy.keys()):\n",
    "            #Create DBSCAN object and apply to each latitude/longitude pair\n",
    "            self.apply_DBSCAN(d_lat_lon_numpy=d_lat_lon_numpy,province=province,epsilon=epsilon,min_samples=min_samples,algorithm = 'ball_tree',metric='haversine')\n",
    "            #Retrieve labels obtained from algorithm\n",
    "            self.retrieve_labels(d_lat_lon_numpy=d_lat_lon_numpy,province=province)\n",
    "            #Obtain cluster labels\n",
    "            self.obtain_cluster_labels(d_lat_lon_numpy=d_lat_lon_numpy,province=province)\n",
    "            #obtain clusters numpy\n",
    "            self.obtain_clusters_numpy(d_lat_lon_numpy=d_lat_lon_numpy,province=province)\n",
    "\n",
    "            # Check for empty clusters, DBSCAN function does not like them\n",
    "            # We edrop any dictionaries with empty clusters to later run them again\n",
    "            # With only one DBSCAN neighbour (no noise)\n",
    "            final_clusters = d_lat_lon_numpy.get(province)[4].get(\"{}_clusters\".format(province))\n",
    "            if len(final_clusters.iloc[-1]) == 0:\n",
    "                final_clusters.drop(final_clusters.tail(1).index,inplace=True)\n",
    "            \n",
    "        for province in list(d_lat_lon_numpy.keys()):\n",
    "\n",
    "            final_clusters = d_lat_lon_numpy.get(province)[4].get(\"{}_clusters\".format(province))\n",
    "            if len(final_clusters) == 0:\n",
    "                del d_lat_lon_numpy[\"{}\".format(province)]\n",
    "                self.replace_dictionary(d_lat_lon_numpy,province,d)\n",
    "                #min_samples_final = 1\n",
    "                #Create DBSCAN object and apply to each latitude/longitude pair\n",
    "                self.apply_DBSCAN(d_lat_lon_numpy=d_lat_lon_numpy,province=province,epsilon=epsilon,min_samples=1,algorithm = 'ball_tree',metric='haversine')\n",
    "                #Retrieve labels obtained from algorithm\n",
    "                self.retrieve_labels(d_lat_lon_numpy=d_lat_lon_numpy,province=province)\n",
    "                #Obtain cluster labels\n",
    "                self.obtain_cluster_labels(d_lat_lon_numpy=d_lat_lon_numpy,province=province)\n",
    "                #obtain clusters numpy\n",
    "                self.obtain_clusters_numpy(d_lat_lon_numpy=d_lat_lon_numpy,province=province)\n",
    "\n",
    "        for province in list(d_lat_lon_numpy.keys()):\n",
    "\n",
    "            final_clusters = d_lat_lon_numpy.get(province)[4].get(\"{}_clusters\".format(province))\n",
    "            if len(final_clusters) > 0 :\n",
    "\n",
    "                d_lat_lon_numpy[\"{}\".format(province)].append(\n",
    "                    {\"{}_centermost_points\".format(province):d_lat_lon_numpy.get(province)[4][\"{}_clusters\".format(province)].map(get_centermost_point)})\n",
    "\n",
    "                #unzip the list of centermost points (lat,lon) tuples into separate lat/lon lists\n",
    "                lats, lons = zip(*d_lat_lon_numpy.get(province)[5][\"{}_centermost_points\".format(province)])\n",
    "                #create a pandas dataframe\n",
    "                rep_points = pd.DataFrame({'lon':lons, 'lat':lats})\n",
    "\n",
    "                d_lat_lon_numpy[\"{}\".format(province)].append({\"{}_centermost_points_numpy\".format(province) : rep_points.to_numpy()})\n",
    "\n",
    "                d_lat_lon_numpy[\"{}\".format(province)].append(\n",
    "                    {\"{}_gdf_cluster_samples\".format(province):gpd.GeoDataFrame(rep_points, geometry=gpd.points_from_xy(rep_points.lon, rep_points.lat),crs = \"EPSG:4326\" )})\n",
    "\n",
    "        return d_lat_lon_numpy\n",
    "\n",
    "    def calculate_mean_ontario_loc(self,d):    \n",
    "        #mean location for ontario cities\n",
    "        mean_lat_on = np.mean(d[\"province_ON\"][\"lat\"])\n",
    "        mean_lng_on = np.mean(d[\"province_ON\"][\"lng\"])\n",
    "        \n",
    "        return mean_lat_on,mean_lng_on\n",
    "\n",
    "    def calculate_mean_canada_loc(self,gdf):\n",
    "        #mean location for canada cities\n",
    "        gdf_mean_lat = np.mean(gdf.lat)\n",
    "        gdf_mean_lng = np.mean(gdf.lng)\n",
    "\n",
    "        return gdf_mean_lat,gdf_mean_lng\n",
    "\n",
    "    def cities_dict(self,d_lat_lon_numpy):\n",
    "        cities = {}\n",
    "        for province in d_lat_lon_numpy.keys():\n",
    "            cities[\"{}\".format(province)] = d_lat_lon_numpy.get(\"{}\".format(province))[0]\n",
    "        \n",
    "        return cities\n",
    "\n",
    "    def clusters_dict(self,d_lat_lon_numpy):\n",
    "        clusters={}\n",
    "        \n",
    "        for province in d_lat_lon_numpy.keys():\n",
    "            #print(d_lat_lon_numpy.get(\"{}\".format(province)))#[6])\n",
    "            clusters[\"{}\".format(province)] = d_lat_lon_numpy.get(\"{}\".format(province))[6].get(\"{}_centermost_points_numpy\".format(province))\n",
    "        \n",
    "        return clusters\n",
    "\n",
    "    def study_area_numpy(self,cities,study_area_provinces):\n",
    "        study_area = []\n",
    "        \n",
    "        for stdy_area in study_area_provinces:\n",
    "            study_area.append(cities[stdy_area])\n",
    "\n",
    "        study_area = np.concatenate(study_area)\n",
    "\n",
    "        return study_area\n",
    "\n",
    "    def cluster_area_numpy(self,clusters,cluster_area_provinces):\n",
    "        cluster_area = []\n",
    "\n",
    "        for clstr_area in cluster_area_provinces:\n",
    "            cluster_area.append(clusters[clstr_area])\n",
    "\n",
    "        cluster_area = np.concatenate(cluster_area)\n",
    "\n",
    "        return cluster_area\n",
    "\n",
    "\n",
    "    def create_map(self,gdf_mean_lat,gdf_mean_lng,study_area,study_clusters,zoom):\n",
    "\n",
    "        my_map = folium.Map(location=[gdf_mean_lat,gdf_mean_lng], zoom_start=zoom)\n",
    "\n",
    "        for point in study_clusters :\n",
    "            loc = [point[1],point[0]]\n",
    "            folium.Marker(location=loc,icon=folium.Icon(color=\"red\")).add_to(my_map)\n",
    "            #folium.Circle(radius=40000,location=[point[1],point[0]],color=\"red\").add_to(my_map)\n",
    "\n",
    "        for point in study_area :\n",
    "            loc = [point[0],point[1]]\n",
    "            #folium.Marker(location=loc,icon=folium.Icon(color=\"blue\")).add_to(my_map)\n",
    "            folium.Circle(radius=4000,location=loc,color=\"BLUE\").add_to(my_map)\n",
    "        \n",
    "        #folium.GeoJson(data = gdf).add_to(my_map)    \n",
    "\n",
    "        return my_map \n",
    "\n",
    "\n",
    "\n",
    "    def get_dict(self):\n",
    "        gdf = self.import_data()\n",
    "        d = self.create_gdf_dictionary(gdf)\n",
    "        provinces = self.obtain_provinces(d)\n",
    "        d_lat_lon_numpy = self.create_numpy_dictionary(d,gdf,provinces)\n",
    "        d_lat_lon_numpy = self.perform_dbscan(d_lat_lon_numpy,epsilon = self.epsilon,min_samples=self.min_samples,d=d)   \n",
    "\n",
    "        return d_lat_lon_numpy \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def run_map(self):\n",
    "        gdf = self.import_data()\n",
    "        d = self.create_gdf_dictionary(gdf)\n",
    "        provinces = self.obtain_provinces(d)\n",
    "        d_lat_lon_numpy = self.create_numpy_dictionary(d,gdf,provinces)\n",
    "        d_lat_lon_numpy = self.perform_dbscan(d_lat_lon_numpy,epsilon = self.epsilon,min_samples=self.min_samples,d=d)\n",
    "        mean_lat_on,mean_lng_on = self.calculate_mean_ontario_loc(d)\n",
    "        gdf_mean_lat, gdf_mean_lng = self.calculate_mean_canada_loc(gdf)\n",
    "        clusters = self.clusters_dict(d_lat_lon_numpy)\n",
    "        cities = self.cities_dict(d_lat_lon_numpy)\n",
    "        study_area = self.study_area_numpy(cities,self.study_area_provinces)\n",
    "        study_clusters = self.cluster_area_numpy(clusters,self.cluster_area_provinces)\n",
    "        map = self.create_map(gdf_mean_lat,gdf_mean_lng,study_area,study_clusters,zoom=5)\n",
    "\n",
    "        return map\n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_area_provinces = ['province_QC', 'province_BC', 'province_AB', 'province_MB', 'province_NS', 'province_SK', 'province_NL', 'province_NB', 'province_PE', 'province_YT', 'province_NT', 'province_NU']\n",
    "cluster_area_provinces = ['province_QC', 'province_BC', 'province_AB', 'province_MB', 'province_NS', 'province_SK', 'province_NL', 'province_NB', 'province_PE', 'province_YT', 'province_NT', 'province_NU']\n",
    "\n",
    "m = dbscan_clustering_canada(epsilon = 0.019, min_samples= 2,study_area_provinces=study_area_provinces,cluster_area_provinces=cluster_area_provinces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.dbscan_clustering_canada at 0x1ad70cf25f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\canadacities.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jreye\\Desktop\\classes_for_elias.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jreye/Desktop/classes_for_elias.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m m\u001b[39m.\u001b[39;49mrun_map()\n",
      "\u001b[1;32mc:\\Users\\jreye\\Desktop\\classes_for_elias.ipynb Cell 5\u001b[0m in \u001b[0;36mdbscan_clustering_canada.run_map\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jreye/Desktop/classes_for_elias.ipynb#W5sZmlsZQ%3D%3D?line=215'>216</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_map\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/jreye/Desktop/classes_for_elias.ipynb#W5sZmlsZQ%3D%3D?line=216'>217</a>\u001b[0m     gdf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimport_data()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jreye/Desktop/classes_for_elias.ipynb#W5sZmlsZQ%3D%3D?line=217'>218</a>\u001b[0m     d \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_gdf_dictionary(gdf)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jreye/Desktop/classes_for_elias.ipynb#W5sZmlsZQ%3D%3D?line=218'>219</a>\u001b[0m     provinces \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobtain_provinces(d)\n",
      "\u001b[1;32mc:\\Users\\jreye\\Desktop\\classes_for_elias.ipynb Cell 5\u001b[0m in \u001b[0;36mdbscan_clustering_canada.import_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jreye/Desktop/classes_for_elias.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m data_path \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mcanadacities.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jreye/Desktop/classes_for_elias.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m#data_pathr\"C:\\Users\\jua12849\\Documents\\GitHub\\GeospatialDataAnalysis\\canadacities.csv\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jreye/Desktop/classes_for_elias.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m canadian_cities \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(data_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jreye/Desktop/classes_for_elias.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m datum \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mEPSG:4326\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jreye/Desktop/classes_for_elias.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m#create geodataframe containing data with all canadian cities and a point geometry column\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jreye\\anaconda3\\envs\\geo_env_test\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jreye\\anaconda3\\envs\\geo_env_test\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\jreye\\anaconda3\\envs\\geo_env_test\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\jreye\\anaconda3\\envs\\geo_env_test\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\jreye\\anaconda3\\envs\\geo_env_test\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m     f,\n\u001b[0;32m   1219\u001b[0m     mode,\n\u001b[0;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1226\u001b[0m )\n\u001b[0;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\jreye\\anaconda3\\envs\\geo_env_test\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\\\canadacities.csv'"
     ]
    }
   ],
   "source": [
    "m.run_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('geo_env_test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b1f06e1063d562f775d07a9e8b4437c71f6b686f2245d4149169357b1524964"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
